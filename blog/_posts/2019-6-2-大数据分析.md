---
layout: post
title: 怎样使信息化社会的大数据分析成为可能？
category: communicate
tags: [学习笔记,大数据]
---

#### 怎样使信息化社会的大数据分析成为可能？


在信息社会的大数据分析中，主要呈现出两个特点：维度高，数据量大。这导致的问题是，计算机性能的迭代更新速度跟不上数据的爆炸增长。

压缩感知基于数据或者接收信号是来源于稀疏的信号的假设，这在现实中是合理的，这样一个假设使得从低维信号重构出高维信号成为可能，也让降低存储空间和计算复杂度成为可能。

现在包括社交网络上的数据呈现出的特点，比如最常见的文本和图片，其实都具备这样的特点，这让我们能从别的角度来减少处理它的难度。

比如一张图片，如果是三通道的，将是一个张量数据。如果我们对它下采样，即使维度降低了一个数量级，这并不会影响我们对它的认识。如果把它变成单通道的，我们也可以利用我们的知识对它高概率的还原。这也是为什么我们说图片“有意义的维度”其实远低于它的尺寸，这让卷积操作变得有意义。所以说，数据是有冗余的，如果我们不停地降维，我们关注的是数据从“量变”到引起“质变”的临界点。

再比如这样一句文本，

“candes做的压缩感距今经十几年了，但在真实景中临的问依然很多。”

上面的这个病句读起来可能会有些别扭，但是并不会影响我们去理解它。事实上，我们在阅读它之前，我们的脑子里对这句话的意义已经有了预期，也就是知识。结构化的知识会让维度的大规模降低成为可能。

当然未来还有很多需要处理的高维数据，比如用户的行为记录，在未来信息化更加彻底的时候，如果记录每一条出行，或者更加详细的行为记录，那么这将是一个维度惊人的数据。那么如何根据用户的记录为用户提供服务呢？
PCA降维是一种找到最具代表性特征的线性方法，但是缺点就是我们在降维的同时会失去大量有意义的信息。因此，构建一个独立，完备的特征基，即解耦问题，将使得以损失最小代价获得最大信息成为可能。

无监督的解耦问题需要结构化知识的辅助，以及这个从“量变”到引起“质变”的临界点的理论理解。

这些问题目前有待解决的的难点是，

1.如何将知识更有效地嵌入到真实数据中？这牵涉到知识图谱。

2.在无监督的特征解耦中，怎么样可以称为保留了更加有意义的信息？对于可以接受的维度降低，降低多少不会使数据失去意义？特征降维，能重构是否一定有意义？

3.什么样的信息提取方式是计算可允许的？

